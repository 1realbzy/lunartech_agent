# LunarTech AI Interview Agent: Technical Brief & Presentation Guide

## 1. COMPLETE PROJECT ARCHITECTURE

### 1.1. File Structure & Purpose

*   **`main.py`**: The core of the application. It orchestrates the entire interview process, from speech recognition and text-to-speech to LLM interaction and data storage.
*   **`config.py`**: A centralized configuration file that allows for easy tuning of application parameters, such as audio settings, interview questions, and file paths. This separation of configuration from logic is a key design decision for maintainability.
*   **`utils.py`**: A collection of utility functions for interacting with the database, exporting data, and testing audio devices. This promotes code reuse and keeps the main application logic clean.
*   **`dashboard.html`**: A static HTML file that visualizes interview statistics. It is generated by `main.py` and provides a simple, effective way to monitor the application's performance.
*   **`data/`**: This directory contains all the data generated by the application, including interview transcripts, summaries, and the SQLite database. This organized structure makes data management straightforward.
*   **`models/`**: This directory stores the speech recognition and language models. Keeping these separate from the application code is crucial for managing large model files.
*   **`requirements.txt`**: Lists all the Python dependencies required to run the project, ensuring a reproducible environment.
*   **`.env` / `.env.template`**: Used for managing environment variables, though not heavily utilized in the current implementation, it's a good practice for future development (e.g., API keys).

### 1.2. Data Flow

1.  **Initiation**: The `main()` function in `main.py` creates an `InterviewAgent` instance.
2.  **Speech Input**: The `listen()` method captures audio from the user's microphone using `pyaudio`.
3.  **Speech-to-Text (STT)**: The captured audio is processed by the Vosk `KaldiRecognizer` to transcribe it into text.
4.  **LLM Processing**: The transcribed text is sent to the `EnhancedLLM` class for analysis. This can involve analyzing the answer's relevance, checking for FAQ matches, or generating a summary.
5.  **Text-to-Speech (TTS)**: The agent's responses are converted to speech using the `pyttsx3` engine via the `speak()` method.
6.  **Data Storage**: At the end of the interview, the entire conversation, summary, and extracted information are saved to a SQLite database (`data/interviews.db`) and also as individual transcript and summary files in the `data/` directory.
7.  **Dashboard Generation**: The `generate_dashboard()` method queries the SQLite database to get statistics and then generates the `dashboard.html` file.

### 1.3. Key Technical Decisions

*   **Offline First**: The decision to use local models (Vosk, and a mock LLM) makes the application independent of internet connectivity and avoids API costs. This is a significant advantage for a standalone application.
*   **SQLite Database**: Using SQLite provides a lightweight, serverless, and self-contained database solution that is perfect for this type of application. It simplifies setup and deployment.
*   **Modular Design**: The separation of concerns into different modules (`main.py`, `config.py`, `utils.py`) makes the code easier to understand, maintain, and extend.
*   **Mock LLM**: The `EnhancedLLM` class is a clever way to simulate a real LLM's functionality without the complexity of setting up and running a large language model locally. This allows for rapid development and testing of the application's logic.

## 2. TECHNICAL IMPLEMENTATION DETAILS

### 2.1. Speech Processing Pipeline (STT/TTS)

*   **STT (Vosk)**: The application uses the Vosk library for speech-to-text. It's an offline, open-source STT engine that is known for its accuracy and performance. The `listen()` method in `main.py` handles the audio capture and transcription process.
*   **TTS (pyttsx3)**: For text-to-speech, the `pyttsx3` library is used. It's a cross-platform, offline TTS library that is easy to use and configure. The `speak()` method encapsulates the TTS functionality.

### 2.2. LLM Integration and Prompt Engineering

*   **Mock LLM (`EnhancedLLM`)**: The `EnhancedLLM` class in `main.py` simulates the behavior of a real LLM. It uses a series of `if/elif` statements to handle different types of prompts, such as analyzing answer quality, matching FAQs, and generating summaries.
*   **Prompt Engineering**: The prompts sent to the `EnhancedLLM` are carefully crafted to elicit the desired response. For example, the summary generation prompt includes clear instructions on the expected output format (summary + JSON data). This demonstrates a good understanding of how to interact with language models.

### 2.3. Database Design and Data Storage

*   **SQLite Database**: The database schema is defined in the `save_to_database()` method in `main.py`. It consists of three tables: `interviews`, `questions_answers`, and `extracted_info`. This normalized structure is efficient for storing and querying the interview data.
*   **File-based Storage**: In addition to the database, the application also saves transcripts and summaries as individual files. This provides a human-readable backup and makes it easy to access the data without querying the database.

### 2.4. Error Handling and Edge Case Management

*   **Graceful Fallbacks**: The speech recognition initialization includes a fallback to Vosk-only mode if the preferred hybrid engine (Whisper) is not available.
*   **Confidence Scoring**: The `calculate_confidence()` method provides a mechanism to assess the quality of the transcription, which can be used to handle uncertain inputs.
*   **Name Spelling Confirmation**: The `confirm_name_spelling()` method is a thoughtful feature that addresses the common challenge of accurately transcribing names, especially non-English ones.

## 3. CODE WALKTHROUGH GUIDE

### 3.1. `main.py`

*   **What it does**: This is the main entry point of the application. It defines the `InterviewAgent` class, which manages the entire interview process.
*   **Key Functions/Classes**:
    *   `EnhancedLLM`: A mock LLM that simulates intelligent responses.
    *   `InterviewAgent`: The main class that orchestrates the interview.
    *   `initialize_speech_recognition()`, `initialize_text_to_speech()`, `initialize_llm()`: These methods set up the core components of the agent.
    *   `conduct_interview()`: This method contains the main interview loop.
    *   `generate_summary()`: This method uses the LLM to generate a summary of the interview.
    *   `save_outputs()`: This method saves the interview data to files and the database.
*   **Technical Highlights**:
    *   The use of a queue and a separate thread for audio recording in `_record_audio()` is a good example of concurrent programming to avoid blocking the main thread.
    *   The state management within the `InterviewAgent` class is well-organized.
*   **Connection Points**:
    *   Imports configuration from `config.py`.
    *   Uses utility functions from `utils.py` (implicitly, as the database is used).
    *   Generates `dashboard.html`.

### 3.2. `dashboard.html`

*   **What it does**: This file provides a visual representation of the interview statistics.
*   **Key Functions/Classes**: Not applicable (static HTML).
*   **Technical Highlights**:
    *   The use of inline CSS is simple and effective for a small, self-contained dashboard.
    *   The dashboard is dynamically generated by `main.py`, which is a good way to create simple reports without a complex web framework.
*   **Connection Points**:
    *   Generated by the `generate_dashboard()` method in `main.py`.

### 3.3. `config.py`

*   **What it does**: Centralizes all the configuration parameters for the application.
*   **Key Functions/Classes**: Not applicable.
*   **Technical Highlights**:
    *   Separating configuration from the application logic makes the code more maintainable and easier to modify.
    *   The use of constants for file paths and other settings is a good practice.
*   **Connection Points**:
    *   Imported by `main.py` and `utils.py`.

### 3.4. `utils.py`

*   **What it does**: Provides utility functions for database management and audio device testing.
*   **Key Functions/Classes**:
    *   `view_interview_data()`: Allows viewing interview data from the command line.
    *   `export_interviews_to_json()`: Exports interview data to a JSON file.
    *   `clear_database()`: A utility to clear the database.
*   **Technical Highlights**:
    *   The command-line interface in the `main()` function is a useful feature for managing the application's data.
*   **Connection Points**:
    *   Interacts with the SQLite database defined in `config.py`.

## 4. INNOVATION & BONUS FEATURES

*   **Dashboard Generation**: The automatic generation of an HTML dashboard is a great feature that provides a user-friendly way to visualize the results.
*   **Name Spelling Confirmation**: This is a thoughtful and practical feature that improves the user experience and data accuracy.
*   **Confidence Scoring**: The implementation of a confidence scoring mechanism for transcriptions is an advanced feature that shows a deeper understanding of the challenges of speech recognition.
*   **Utility Script (`utils.py`)**: The inclusion of a utility script with a command-line interface for managing the database is a professional touch that makes the project more robust.

## 5. PRESENTATION TALKING POINTS

### 5.1. Business Impact

*   **Automation of Screening**: This tool can automate the initial screening of candidates, saving significant time for recruiters.
*   **Data-Driven Decisions**: The structured data and dashboard provide insights that can help in making more informed hiring decisions.
*   **Consistency**: The AI agent ensures that every candidate is asked the same questions in the same way, reducing bias in the initial screening process.

### 5.2. Scalability and Integration

*   **Scalability**: The application can be scaled by replacing the mock LLM with a more powerful local or cloud-based model. The database can also be upgraded to a more robust solution like PostgreSQL if needed.
*   **Integration**: The project can be integrated with other HR systems through APIs. The data export functionality in `utils.py` is a first step towards this.

### 5.3. Competitive Advantages

*   **Offline Capability**: The ability to run completely offline is a major advantage in environments with limited or unreliable internet access.
*   **Cost-Effective**: By using open-source and local models, the solution avoids the recurring costs of cloud-based APIs.
*   **Customizability**: The modular design and centralized configuration make it easy to customize the interview questions, language models, and other parameters to fit specific needs.
